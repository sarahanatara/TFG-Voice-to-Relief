ğŸš¨ Emergency ASR - Sistema de TranscripciÃ³n de Emergencias MultilingÃ¼e
Sistema robusto de Automatic Speech Recognition (ASR) para transcripciÃ³n de llamadas de emergencia en mÃºltiples idiomas, diseÃ±ado como Trabajo de Fin de Grado (TFG).

ğŸŒŸ CaracterÃ­sticas Principales
MultilingÃ¼ismo: Soporte para EspaÃ±ol, Asturiano, Ãrabe, GuaranÃ­ y FrancÃ©s

Robustez: Entrenado con augmentaciÃ³n realista para condiciones adversas

DetecciÃ³n de Emergencias: IdentificaciÃ³n automÃ¡tica de frases crÃ­ticas

Fine-tuning Efficient: Usa LoRA (Low-Rank Adaptation) para entrenamiento eficiente

EvaluaciÃ³n Comprehensiva: MÃ©tricas por idioma, nivel de ruido y escenario

ğŸ—ï¸ Estructura del Proyecto
text
emergency-asr-tfg/
â”œâ”€â”€ configs/                 # Configuraciones
â”‚   â”œâ”€â”€ augment_config.json
â”‚   â”œâ”€â”€ training_config.json
â”‚   â””â”€â”€ languages.json
â”œâ”€â”€ data/                   # Datos y audios
â”‚   â”œâ”€â”€ raw/               # Audios originales por idioma
â”‚   â”œâ”€â”€ noise/             # Ruidos para augmentaciÃ³n
â”‚   â””â”€â”€ generated/         # Datos aumentados
â”œâ”€â”€ src/                   # CÃ³digo fuente
â”‚   â”œâ”€â”€ data_preparation/
â”‚   â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ inference/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ scripts/               # Scripts de ejecuciÃ³n
â”‚   â”œâ”€â”€ 01_prepare_data.py
â”‚   â”œâ”€â”€ 02_run_augmentation.py
â”‚   â”œâ”€â”€ 03_train_model.py
â”‚   â”œâ”€â”€ 04_evaluate.py
â”‚   â””â”€â”€ 05_demo.py
â”œâ”€â”€ notebooks/             # AnÃ¡lisis y experimentos
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_augmentation_analysis.ipynb
â”‚   â””â”€â”€ 03_results_analysis.ipynb
â”œâ”€â”€ models/               # Modelos entrenados
â””â”€â”€ logs/                 # Logs de entrenamiento
ğŸš€ InstalaciÃ³n RÃ¡pida
1. Clonar y configurar entorno
bash
git clone <repository-url>
cd emergency-asr-tfg
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows
2. Instalar dependencias
bash
pip install -r requirements.txt
3. Preparar estructura de datos
bash
mkdir -p data/raw data/noise data/generated models logs
ğŸ“Š Pipeline Completo
Paso 1: PreparaciÃ³n de Datos
bash
python scripts/01_prepare_data.py
Valida archivos de audio y transcripciones

Genera metadata inicial

Analiza distribuciÃ³n por idioma

Paso 2: AugmentaciÃ³n
bash
python scripts/02_run_augmentation.py
Mezcla ruidos realistas (trÃ¡fico, sirenas, multitudes)

Aplica efectos acÃºsticos (reverb, telephone effect)

Genera mÃºltiples variantes por audio

Paso 3: Entrenamiento
bash
python scripts/03_train_model.py
Fine-tuning con LoRA para eficiencia

Entrenamiento multilingÃ¼e

Early stopping y checkpointing

Paso 4: EvaluaciÃ³n
bash
python scripts/04_evaluate.py
WER por idioma y nivel de ruido

DetecciÃ³n de frases de emergencia

Reporte comprehensivo

Paso 5: Demo
bash
python scripts/05_demo.py
Interfaz Gradio para pruebas

TranscripciÃ³n en tiempo real

DetecciÃ³n de emergencias

ğŸ—£ï¸ Idiomas Soportados
Idioma	CÃ³digo	Ejemplo Frases Emergencia
EspaÃ±ol	es	"ayuda", "emergencia", "ambulancia"
Asturiano	ast	"ayuda", "emerxencia", "ambulancia"
Ãrabe	ar	"Ù…Ø³Ø§Ø¹Ø¯Ø©", "Ø·ÙˆØ§Ø±Ø¦", "Ø¥Ø³Ø¹Ø§Ù"
GuaranÃ­	gn	"pytyvÃµ", "emergencia", "ambulancia"
FrancÃ©s	fr	"aide", "urgence", "ambulance"
ğŸ¯ AugmentaciÃ³n de Audio
El sistema aplica augmentaciÃ³n realista para simular condiciones de emergencia:

Niveles de Ruido
clean: SNR 30-40 dB (condiciones ideales)

low_noise: SNR 20-30 dB (ruido bajo)

medium_noise: SNR 10-20 dB (ruido moderado)

high_noise: SNR 0-10 dB (ruido alto)

extreme_noise: SNR -5-5 dB (condiciones extremas)

Escenarios de Emergencia
street_accident: TrÃ¡fico, sirenas, gritos

home_emergency: ElectrodomÃ©sticos, voces, telÃ©fono

public_space: MÃºsica, multitudes, ambiente

nature_emergency: Viento, lluvia, truenos

Efectos AcÃºsticos
Reverb (simulaciÃ³n de espacios)

Pitch shift (variaciÃ³n de tono)

Time stretch (cambio de velocidad)

Telephone effect (filtro banda limitada)

Packet loss (simulaciÃ³n VoIP)

ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n
MÃ©tricas Principales
WER (Word Error Rate): PrecisiÃ³n general de transcripciÃ³n

CER (Character Error Rate): PrecisiÃ³n a nivel de caracteres

DetecciÃ³n de Emergencias: Precision, Recall, F1-score

Robustez: DegradaciÃ³n bajo diferentes niveles de ruido

EvaluaciÃ³n por CategorÃ­a
Por idioma

Por nivel de ruido

Por escenario de emergencia

Por frase de emergencia especÃ­fica

ğŸ› ï¸ Uso Avanzado
Entrenamiento Personalizado
python
from src.training.lora_trainer import MultilingualLoRATrainer
from src.utils.config_loader import load_config

# Cargar configuraciones
train_config = load_config("training_config")
languages = load_config("languages")["languages"]

# Inicializar trainer
trainer = MultilingualLoRATrainer(
    train_config=train_config,
    languages=languages,
    base_model="openai/whisper-small"
)

# Entrenar
trainer.train("data/generated/train_metadata.csv", "data/generated/val_metadata.csv")
TranscripciÃ³n ProgramÃ¡tica
python
from src.inference.transcriber import EmergencyTranscriber
from src.utils.config_loader import load_config

# Cargar configuraciones
languages_config = load_config("languages")

# Inicializar transcriber
transcriber = EmergencyTranscriber("models/whisper-lora", languages_config)

# Transcribir audio
result = transcriber.transcribe("audio_emergencia.wav")
print(f"TranscripciÃ³n: {result['transcription']}")
print(f"Emergencia detectada: {result['is_emergency']}")
print(f"Frases detectadas: {result['emergency_phrases']}")
AnÃ¡lisis de Resultados
python
from src.evaluation.analyzer import ComprehensiveEvaluator
from src.utils.config_loader import load_config

# Cargar configuraciones
languages_config = load_config("languages")

# Evaluar modelo
evaluator = ComprehensiveEvaluator("models/whisper-lora", languages_config)
results = evaluator.run_comprehensive_evaluation("data/generated/test_metadata.csv")

# Generar reporte
evaluator.generate_report(results, "evaluation_report.html")
ğŸ”§ ConfiguraciÃ³n
Ajuste de HiperparÃ¡metros
Editar configs/training_config.json:

json
{
  "training": {
    "num_train_epochs": 5,
    "learning_rate": 1e-4,
    "per_device_train_batch_size": 4,
    "gradient_accumulation_steps": 2
  },
  "lora": {
    "r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05
  }
}
PersonalizaciÃ³n de AugmentaciÃ³n
Editar configs/augment_config.json:

json
{
  "augmentation": {
    "n_variants_per_file": 25,
    "snr_levels": {
      "clean": [30, 40],
      "high_noise": [0, 10]
    },
    "emergency_scenarios": {
      "street_accident": ["trafico", "sirena", "gritos"]
    }
  }
}
ğŸ“Š Resultados Esperados
Rendimiento General
WER en condiciones limpias: < 0.15

WER en condiciones extremas: < 0.30

DetecciÃ³n de emergencias: > 0.85 F1-score

Consistencia multilingÃ¼e: Rendimiento similar entre idiomas

MÃ©tricas de Robustez
DegradaciÃ³n mÃ¡xima de WER: < 0.15 entre condiciones limpias y extremas

DetecciÃ³n confiable de frases crÃ­ticas incluso con ruido

TranscripciÃ³n aceptable con SNR hasta 0 dB

ğŸ› SoluciÃ³n de Problemas
Error: Memoria insuficiente
bash
# Reducir batch size
python scripts/03_train_model.py --batch_size 2

# Usar modelo mÃ¡s pequeÃ±o
python scripts/03_train_model.py --model_name openai/whisper-tiny
Error: Archivos de audio no encontrados
bash
# Verificar estructura de datos
python scripts/01_prepare_data.py

# Regenerar metadata
rm data/raw_metadata.csv
python scripts/01_prepare_data.py
Error: Dependencias faltantes
bash
# Reinstalar requirements
pip install -r requirements.txt --force-reinstall

# Instalar individualmente paquetes problemÃ¡ticos
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118
ğŸ¤ ContribuciÃ³n
Para contribuir al proyecto:

Fork el repositorio

Crea una rama para tu feature (git checkout -b feature/AmazingFeature)

Commit tus cambios (git commit -m 'Add some AmazingFeature')

Push a la rama (git push origin feature/AmazingFeature)

Abre un Pull Request

ğŸ“ Licencia
Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo LICENSE para detalles.

ğŸ™ Agradecimientos
OpenAI por el modelo Whisper

Hugging Face por la biblioteca Transformers

PyTorch por el framework de deep learning

Agradecimientos especiales a todos los colaboradores que grabaron audios en mÃºltiples idiomas

ğŸ“ Contacto y Soporte
Para preguntas acadÃ©micas o tÃ©cnicas sobre este proyecto TFG:

Autor: [Sara Hanafy TÃ¡rano]

Email: [UO287527@uniovi.es]

Universidad: [Universidad de Oviedo]

Departamento: [Departamento de informÃ¡tica, Grado en Ciencia e IngenierÃ­a de Datos]

Nota: Este proyecto es parte de un Trabajo de Fin de Grado. Los resultados pueden variar dependiendo de la calidad y cantidad de datos de entrenamiento disponibles.#   T F G - V o i c e - t o - R e l i e f  
 